{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pprint\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from azure_cfg import api_key\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = api_key\n",
    "\n",
    "vision_base_url = \"https://westcentralus.api.cognitive.microsoft.com/vision/v1.0/\"\n",
    "vision_analyze_url = vision_base_url + \"analyze?\"\n",
    "\n",
    "image_dir = './images/'\n",
    "train_image_dir = './images/train/'\n",
    "test_image_dir = './images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_high_level_features(image_path):\n",
    "    headers  = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "                'Content-Type'             : 'application/octet-stream'}\n",
    "    params   = {'visualFeatures': 'Adult,Categories,Description,Color,Faces,ImageType,Tags'}\n",
    "    body     = open(image_path, 'rb')\n",
    "\n",
    "    response = requests.post(vision_analyze_url, headers=headers, params=params, data=body)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    return {\n",
    "        \"clip_art_type\"                      : data[\"imageType\"][\"clipArtType\"],\n",
    "        \"line_drawing_type\"                  : data[\"imageType\"][\"lineDrawingType\"],\n",
    "        \"is_black_and_white\"                 : int(data[\"color\"][\"isBwImg\"]),\n",
    "        \"is_adult_content\"                   : int(data[\"adult\"][\"isAdultContent\"]),\n",
    "        \"adult_score\"                        : data[\"adult\"][\"adultScore\"],\n",
    "        \"is_racy\"                            : int(data[\"adult\"][\"isRacyContent\"]),\n",
    "        \"racy_score\"                         : data[\"adult\"][\"racyScore\"],\n",
    "        \"has_faces\"                          : int(len(data[\"faces\"])),\n",
    "        \"num_faces\"                          : len(data[\"faces\"]),\n",
    "        \"is_dominant_color_background_black\" : int(data[\"color\"][\"dominantColorBackground\"] == \"Black\"),\n",
    "        \"is_dominant_color_foreground_black\" : int(data[\"color\"][\"dominantColorForeground\"] == \"Black\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 128, 64\n",
    "descriptor = cv2.HOGDescriptor(_winSize = (width,height),\n",
    "                               _blockSize = (16,16),\n",
    "                               _blockStride = (8,8),\n",
    "                               _cellSize = (8,8),\n",
    "                               _nbins = 9)\n",
    "\n",
    "def extract_low_level_features(image_path, descriptor=descriptor):\n",
    "    image = io.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (width,height))\n",
    "\n",
    "    hog = descriptor.compute(image)\n",
    "    hog = hog.flatten()\n",
    "    return hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label(image_path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(image_dir):\n",
    "    for image_path in os.listdir(image_dir):\n",
    "        path = image_dir + image_path\n",
    "\n",
    "        high_level_features = extract_high_level_features(path)\n",
    "        low_level_features = extract_low_level_features(path)\n",
    "\n",
    "        features = np.array(list(high_level_features.values()))\n",
    "        features = np.append(features, low_level_features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './images/VizWiz_train_000000000096.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-bd24bb502a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-2a20047ccd94>\u001b[0m in \u001b[0;36mextract_all_features\u001b[0;34m(image_paths)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mhigh_level_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_high_level_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlow_level_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_low_level_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-0c52d6bfd436>\u001b[0m in \u001b[0;36mextract_high_level_features\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m                 'Content-Type'             : 'application/octet-stream'}\n\u001b[1;32m      4\u001b[0m     \u001b[0mparams\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'visualFeatures'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Adult,Categories,Description,Color,Faces,ImageType,Tags'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbody\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvision_analyze_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/VizWiz_train_000000000096.jpg'"
     ]
    }
   ],
   "source": [
    "train_features = extract_all_features(train_image_dir)\n",
    "test_features = extract_all_features(test_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3781</th>\n",
       "      <th>3782</th>\n",
       "      <th>3783</th>\n",
       "      <th>3784</th>\n",
       "      <th>3785</th>\n",
       "      <th>3786</th>\n",
       "      <th>3787</th>\n",
       "      <th>3788</th>\n",
       "      <th>3789</th>\n",
       "      <th>3790</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.065769</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.089652</td>\n",
       "      <td>0.194971</td>\n",
       "      <td>0.336087</td>\n",
       "      <td>0.197564</td>\n",
       "      <td>0.194937</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>0.09141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 3791 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3         4     5     6         7     8     9     \\\n",
       "0   0.0   0.0   1.0   0.0  0.014061   0.0   0.0  0.013014   1.0   0.0   \n",
       "\n",
       "    ...         3781      3782      3783      3784      3785      3786  \\\n",
       "0   ...     0.018814  0.065769  0.004625  0.089652  0.194971  0.336087   \n",
       "\n",
       "       3787      3788      3789     3790  \n",
       "0  0.197564  0.194937  0.123565  0.09141  \n",
       "\n",
       "[1 rows x 3791 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from IPython.display import display\n",
    "\n",
    "features = np.array(list(high_level_features.values()))\n",
    "features = np.append(features, low_level_features)\n",
    "\n",
    "df = DataFrame(data=np.reshape(features, (1,len(features))))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
